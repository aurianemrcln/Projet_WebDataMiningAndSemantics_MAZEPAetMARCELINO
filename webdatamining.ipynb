{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Web scrapping, knowledge base construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Web scrapping and knowledge base construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import inflect\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from datasets import load_dataset\n",
    "\n",
    "import spacy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "We laod the CoNLL-2003 from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Access the training, validation, and test sets\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Print the first example from the training set\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 : Model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Text cleaning and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "\n",
    "p = inflect.engine()\n",
    "# convert number into words\n",
    "def convert_number(text):\n",
    "    # split string into list of words\n",
    "    temp_str = text.split()\n",
    "    # initialise empty list\n",
    "    new_string = []\n",
    "\n",
    "    for word in temp_str:\n",
    "        # if word is a digit, convert the digit\n",
    "        # to numbers and append into the new_string list\n",
    "        if word.isdigit():\n",
    "            temp = p.number_to_words(word)\n",
    "            new_string.append(temp)\n",
    "\n",
    "        # append the word as it is\n",
    "        else:\n",
    "            new_string.append(word)\n",
    "\n",
    "    # join the words of new_string to form a string\n",
    "    temp_str = ' '.join(new_string)\n",
    "    return temp_str\n",
    "\n",
    "def replace_non_alphabetic_with_whitespace(text):\n",
    "    modified_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    return modified_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet') \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(example):\n",
    "    text = \" \".join(example['tokens'])\n",
    "\n",
    "    text = text_lowercase(text)\n",
    "    text = convert_number(text)\n",
    "    text = replace_non_alphabetic_with_whitespace(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_whitespace(text)\n",
    "\n",
    "    # Convertir la liste en chaîne après avoir supprimé les stopwords\n",
    "    text = \" \".join(remove_stopwords(text))\n",
    "    text = \" \".join(stem_words(text))\n",
    "    text = \" \".join(lemma_words(text))\n",
    "    \n",
    "    processed_example = {'tokens': text.split(), 'ner_tags': example['ner_tags']}\n",
    "    return processed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cdcfb4f7d94c4fb9892c8d71b07523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d1b1b98a6d4fff9388db5402e2fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ['0', '1', '2', '3', '4'], 'tokens': [['eu', 'reject', 'german', 'call', 'boycott', 'british', 'lamb'], ['peter', 'blackburn'], ['brussel'], ['european', 'commiss', 'said', 'thursday', 'disagre', 'german', 'advic', 'consum', 'shun', 'british', 'lamb', 'scientist', 'determin', 'whether', 'mad', 'cow', 'diseas', 'transmit', 'sheep'], ['germani', 'repres', 'european', 'union', 'veterinari', 'committe', 'werner', 'zwingmann', 'said', 'wednesday', 'consum', 'buy', 'sheepmeat', 'countri', 'britain', 'scientif', 'advic', 'clearer']], 'pos_tags': [[22, 42, 16, 21, 35, 37, 16, 21, 7], [22, 22], [22, 11], [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7], [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 22, 38, 15, 22, 24, 20, 37, 21, 15, 24, 16, 15, 22, 15, 12, 16, 21, 38, 17, 7]], 'chunk_tags': [[11, 21, 11, 12, 21, 22, 11, 12, 0], [11, 12], [11, 12], [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0], [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 12, 21, 13, 11, 12, 21, 22, 11, 13, 11, 1, 13, 11, 17, 11, 12, 12, 21, 1, 0]], 'ner_tags': [[3, 0, 7, 0, 0, 0, 7, 0, 0], [1, 2], [5, 0], [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "train_processed = train_dataset.map(preprocess_pipeline)\n",
    "validation_processed = validation_dataset.map(preprocess_pipeline)\n",
    "test_processed = test_dataset.map(preprocess_pipeline)\n",
    "\n",
    "print(train_processed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditional Random Field (CRF) with sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.86      0.80      0.83      1668\n",
      "      B-MISC       0.83      0.75      0.79       702\n",
      "       B-ORG       0.77      0.73      0.75      1661\n",
      "       B-PER       0.83      0.85      0.84      1617\n",
      "       I-LOC       0.82      0.66      0.73       257\n",
      "      I-MISC       0.71      0.68      0.69       216\n",
      "       I-ORG       0.69      0.76      0.72       835\n",
      "       I-PER       0.87      0.95      0.91      1156\n",
      "           O       0.99      0.99      0.99     38323\n",
      "\n",
      "    accuracy                           0.96     46435\n",
      "   macro avg       0.82      0.80      0.80     46435\n",
      "weighted avg       0.96      0.96      0.96     46435\n",
      "\n",
      "Precision: 0.9557, Recall: 0.9559, F1-score: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# Define features and labels for training\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        if isinstance(word1, str):  # Vérifiez que word1 est une chaîne de caractères\n",
    "            features.update({\n",
    "                '+1:word.lower()': word1.lower(),\n",
    "                '+1:word.istitle()': word1.istitle(),\n",
    "                '+1:word.isupper()': word1.isupper(),\n",
    "                '+1:postag': postag1,\n",
    "                '+1:postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: word1 is not a string at index {i+1}: {word1}\")\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "pos_tag_dict = dataset[\"train\"].features[\"pos_tags\"].feature.int2str\n",
    "ner_tag_dict = dataset[\"train\"].features[\"ner_tags\"].feature.int2str\n",
    "\n",
    "# Convert dataset into structured format with string POS and NER tags\n",
    "train_sents = [\n",
    "    list(zip(tokens, map(pos_tag_dict, pos_tags), map(ner_tag_dict, ner_tags)))\n",
    "    for tokens, pos_tags, ner_tags in zip(train_dataset[\"tokens\"], train_dataset[\"pos_tags\"], train_dataset[\"ner_tags\"])\n",
    "]\n",
    "\n",
    "test_sents = [\n",
    "    list(zip(tokens, map(pos_tag_dict, pos_tags), map(ner_tag_dict, ner_tags)))\n",
    "    for tokens, pos_tags, ner_tags in zip(test_dataset[\"tokens\"], test_dataset[\"pos_tags\"], test_dataset[\"ner_tags\"])\n",
    "]\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "\n",
    "# Train the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))\n",
    "\n",
    "y_test_flat = list(chain(*y_test))\n",
    "y_pred_flat = list(chain(*y_pred))\n",
    "\n",
    "# Calculer les métriques\n",
    "precision_crf, recall_crf, f1_score_crf, _ = precision_recall_fscore_support(\n",
    "    y_test_flat, y_pred_flat, average='weighted'\n",
    ")\n",
    "\n",
    "print(f\"Precision: {precision_crf:.4f}, Recall: {recall_crf:.4f}, F1-score: {f1_score_crf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.7.5 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy NER Model - Precision: 0.8090, Recall: 0.8168, F1-score: 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "true_entities = []\n",
    "pred_entities = []\n",
    "nlp = spacy.load(\"./best_ner_model\")\n",
    "\n",
    "for text, true_labels in zip(test_dataset[\"tokens\"], test_dataset[\"ner_tags\"]):\n",
    "    text_str = \" \".join(text)\n",
    "    doc = nlp(text_str)\n",
    "    \n",
    "    # Convert true labels to named entity format\n",
    "    true_labels = [ner_tag_dict(label) for label in true_labels]  \n",
    "    true_entities.append(true_labels)\n",
    "    \n",
    "    # Initialiser les labels prédits avec 'O' (Outside)\n",
    "    predicted_labels = [\"O\"] * len(text)\n",
    "    \n",
    "    # Associer les entités détectées aux tokens\n",
    "    for ent in doc.ents:\n",
    "        ent_text = ent.text.split()  # Séparer en tokens\n",
    "        for token in ent_text:\n",
    "            if token in text:  # Vérifier si le token est bien dans le texte d'origine\n",
    "                idx = text.index(token)  # Trouver l'index du token\n",
    "                predicted_labels[idx] = ent.label_  # Assigner l'entité\n",
    "        \n",
    "    pred_entities.append(predicted_labels)\n",
    "\n",
    "precision_spaCy, recall_spaCy, f1_spaCy, _ = precision_recall_fscore_support(\n",
    "    [label for sent in true_entities for label in sent], \n",
    "    [label for sent in pred_entities for label in sent], \n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "print(f\"spaCy NER Model - Precision: {precision_spaCy:.4f}, Recall: {recall_spaCy:.4f}, F1-score: {f1_spaCy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparition of the performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>CRF</th>\n",
       "      <th>spaCy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.955725</td>\n",
       "      <td>0.808966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.955938</td>\n",
       "      <td>0.816776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.955620</td>\n",
       "      <td>0.812852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric       CRF     spaCy\n",
       "0  Precision  0.955725  0.808966\n",
       "1     Recall  0.955938  0.816776\n",
       "2   F1-Score  0.955620  0.812852"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1-Score'],\n",
    "    'CRF': [precision_crf, recall_crf, f1_score_crf],\n",
    "    'spaCy': [precision_spaCy, recall_spaCy, f1_spaCy]\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the CRF model has a better score for these 3 metrics, which means that CRF performs better than spaCy overall for the named entity recognition task on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the extracted entities along their positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted from CRF model saved in crf_entities.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extraire les entités prédites par CRF\n",
    "crf_entities = []\n",
    "for sent, labels in zip(test_sents, y_pred):\n",
    "    for i, label in enumerate(labels):\n",
    "        if label != 'O':  # Exclure les tokens non annotés\n",
    "            crf_entities.append({\n",
    "                \"text\": sent[i][0],\n",
    "                \"entity\": label,\n",
    "                \"position\": i\n",
    "            })\n",
    "\n",
    "# Sauvegarde en JSON\n",
    "with open(\"crf_entities.json\", \"w\") as f:\n",
    "    json.dump(crf_entities, f, indent=4)\n",
    "\n",
    "print(\"Entities extracted from CRF model saved in crf_entities.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted from spaCy model saved in spacy_entities.json\n"
     ]
    }
   ],
   "source": [
    "spacy_entities = []\n",
    "\n",
    "for text in test_dataset[\"tokens\"]:\n",
    "    sentence = \" \".join(text)\n",
    "    doc = nlp(sentence)\n",
    "    for ent in doc.ents:\n",
    "        spacy_entities.append({\n",
    "            \"text\": ent.text,\n",
    "            \"entity\": ent.label_,\n",
    "            \"start\": ent.start_char,\n",
    "            \"end\": ent.end_char\n",
    "        })\n",
    "\n",
    "# Sauvegarde en JSON\n",
    "with open(\"spacy_entities.json\", \"w\") as f:\n",
    "    json.dump(spacy_entities, f, indent=4)\n",
    "\n",
    "print(\"Entities extracted from spaCy model saved in spacy_entities.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Relation Extraction (RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relations extraites: [('Commission', 'said', 'Thursday'), ('He', 'said', 'Fischler'), ('Fischler', 'proposed', 'reports'), ('Palacio', 'accused', 'meeting'), ('farmers', 'denied', 'Thursday'), ('Jones', 'said', 'radio'), ('Germany', 'imported', 'Britain'), ('Hendrix', 'sells', '17,000'), ('draft', 'sold', '17,000'), ('draft', 'sold', 'Thursday')]\n"
     ]
    }
   ],
   "source": [
    "def extract_relations_from_dataset(dataset):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    relations = []\n",
    "    \n",
    "    for example in dataset:\n",
    "        text = \" \".join(example[\"tokens\"])  # Reconstituer la phrase à partir des tokens\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        for token in doc:\n",
    "            if (token.dep_ == \"nsubj\" or token.dep_ == \"nsubjpass\") and token.head.dep_ == \"ROOT\":\n",
    "                subject = token.text\n",
    "                predicate = token.head.text  # Verbe principal                \n",
    "                for child in token.head.children:\n",
    "                    if child.dep_ in [\"prep\", \"agent\"]:  # Préposition ou agent\n",
    "                        for obj in child.children:\n",
    "                            if obj.dep_ == \"pobj\":  # Objet de la préposition\n",
    "                                relations.append((subject, predicate, obj.text))\n",
    "    \n",
    "    return relations\n",
    "\n",
    "# Exemple d'utilisation avec un dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "extracted_relations = extract_relations_from_dataset(train_dataset)\n",
    "print(\"Relations extraites:\", extracted_relations[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Knowledge graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_graph_from_relations(extracted_relations, word_to_find):\n",
    "    # Create a new RDF graph\n",
    "    g = Graph()\n",
    "\n",
    "    # Define namespaces\n",
    "    EX = Namespace(\"http://example.org/\")\n",
    "\n",
    "    # Ajouter les triplets au graphe\n",
    "    for subj, pred, obj in extracted_relations:\n",
    "        g.add((URIRef(EX[subj]), URIRef(EX[pred]), URIRef(EX[obj])))\n",
    "\n",
    "    # Afficher les triplets RDF\n",
    "    # print(g.serialize(format=\"turtle\"))\n",
    "\n",
    "\n",
    "    # Perform a SPARQL query\n",
    "    query = \"\"\"\n",
    "    PREFIX ex: <http://example.org/>\n",
    "    SELECT ?subject ?predicate\n",
    "    WHERE {\n",
    "        ?subject ?predicate <http://example.org/\"\"\" + word_to_find + \"\"\">\n",
    "    }\n",
    "    \"\"\"\n",
    "    for row in g.query(query):\n",
    "        print(f\"{row.subject} {row.predicate} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://example.org/He http://example.org/said \n"
     ]
    }
   ],
   "source": [
    "knowledge_graph_from_relations(extracted_relations, \"Fischler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_star_wars = \"Star Wars IV is a Movie where there are different kinds of creatures, like humans and wookies. Some creatures are Jedis; for instance, the human Luke is a Jedi, and Master Yoda - for whom the species is not known - is also a Jedi. The wookie named Chewbacca is Han's co-pilot on the Millennium Falcon starship. The speed of Millennium Falcon is 1.5 (above the speed of light!)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.7.5 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: [('Star Wars IV', 'ORG', 0, 12), ('Movie', 'PER', 18, 23), ('Jedis', 'PER', 114, 119), ('Luke', 'PER', 145, 149), ('Jedi', 'PER', 155, 159), ('Master Yoda', 'PER', 165, 176), ('Jedi', 'PER', 225, 229), ('Chewbacca', 'LOC', 248, 257), ('Millennium Falcon', 'ORG', 283, 300), ('Millennium Falcon', 'PER', 324, 341)]\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy's pre-trained NER model\n",
    "nlp = spacy.load(\"./best_ner_model\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text_star_wars)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents]\n",
    "print(\"Extracted Entities:\", entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relations extraites: [('IV', 'is', 'Movie'), ('creatures', 'are', 'Jedis'), ('Luke', 'is for', 'instance'), ('Luke', 'is', 'Jedi'), ('Yoda', 'is', 'Jedi'), ('species', 'known for', 'whom'), ('wookie', 'is', 'co'), ('wookie', 'is', '-'), ('wookie', 'is', 'pilot'), ('wookie', 'is on', 'starship'), ('speed', 'is', '1.5')]\n"
     ]
    }
   ],
   "source": [
    "def extract_relations_from_text(text):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    relations = []\n",
    "    for token in doc:\n",
    "        if token.dep_ in [\"nsubj\", \"nsubjpass\"] and token.head.pos_ in [\"VERB\", \"AUX\", \"ROOT\"]:\n",
    "            subject = token.text\n",
    "            predicate = token.head.text\n",
    "            # Explorer les compléments pour identifier les objets et attributs\n",
    "            for child in token.head.children:\n",
    "                if child.dep_ in [\"dobj\", \"attr\", \"acomp\"]:\n",
    "                    relations.append((subject, predicate, child.text))\n",
    "                \n",
    "                elif child.dep_ == \"prep\" or child.dep_ == \"agent\":  # Gérer les relations prépositionnelles\n",
    "                    for obj in child.children:\n",
    "                        if obj.dep_ == \"pobj\":\n",
    "                            relations.append((subject, f\"{predicate} {child.text}\", obj.text))\n",
    "\n",
    "        # Gérer les relations attributives directes (ex: \"Luke is a Jedi\")\n",
    "        if token.dep_ in [\"attr\", \"appos\"] and token.head.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
    "            relations.append((token.head.text, \"is\", token.text))\n",
    "    \n",
    "    return relations\n",
    "\n",
    "extracted_relations = extract_relations_from_text(text_star_wars)\n",
    "print(\"Relations extraites:\", extracted_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Pipeline for knowledge graph construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Fetch news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ./books/book_1.txt\n",
      "Saved: ./books/book_2.txt\n",
      "Saved: ./books/book_3.txt\n",
      "Saved: ./books/book_4.txt\n",
      "Saved: ./books/book_5.txt\n",
      "Saved: ./books/book_6.txt\n",
      "Saved: ./books/book_7.txt\n",
      "Saved: ./books/book_8.txt\n",
      "Saved: ./books/book_9.txt\n",
      "Saved: ./books/book_10.txt\n",
      "Scraping complete!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "\n",
    "NB_BOOKS = 10  # Number of books to scrape\n",
    "EXPORT_PATH = \"./books/\"\n",
    "\n",
    "url = \"https://www.goodreads.com/list/show/1.Best_Books_Ever\"  # Best Books Ever list\n",
    "\n",
    "options = webdriver.FirefoxOptions()\n",
    "options.headless = True  \n",
    "browser = webdriver.Firefox(options=options)\n",
    "\n",
    "try:\n",
    "    browser.get(url)\n",
    "    time.sleep(5)  # To allow time for page to load\n",
    "\n",
    "    books_data = []\n",
    "    while len(books_data) < NB_BOOKS:\n",
    "        soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        # Find book listings\n",
    "        for book_item in soup.select('a.bookTitle')[:NB_BOOKS - len(books_data)]:\n",
    "            title = book_item.get_text(strip=True)\n",
    "            link = \"https://www.goodreads.com\" + book_item['href']\n",
    "\n",
    "            books_data.append((title, link))\n",
    "\n",
    "        # If we haven't scraped enough books, go to the next page\n",
    "        next_page = soup.select_one('.next a')\n",
    "        if next_page:\n",
    "            next_url = \"https://www.goodreads.com\" + next_page['href']\n",
    "            browser.get(next_url)\n",
    "            time.sleep(5)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    if not os.path.exists(EXPORT_PATH):\n",
    "        os.makedirs(EXPORT_PATH)\n",
    "\n",
    "    for idx, (title, link) in enumerate(books_data[:NB_BOOKS]):\n",
    "        browser.get(link)\n",
    "        time.sleep(3) \n",
    "\n",
    "        book_soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "\n",
    "        author_tag = book_soup.select_one('.BookPageMetadataSection__contributor .ContributorLink__name')\n",
    "        author = author_tag.get_text(strip=True) if author_tag else \"Unknown\"\n",
    "\n",
    "        date_tag = book_soup.select_one('.BookDetails .FeaturedDetails p[data-testid=\"publicationInfo\"]')\n",
    "        release_date = date_tag.get_text(strip=True) if date_tag else \"Unknown\"\n",
    "\n",
    "        summary_tag = book_soup.select_one('.BookPageMetadataSection__description')\n",
    "        summary = summary_tag.get_text(\"\\n\", strip=True) if summary_tag else \"No summary available.\"\n",
    "        \n",
    "        summary = summary.replace(\"Show more\", \"\").strip()\n",
    "        release_date=release_date.replace(\"First published\", \"\").strip()\n",
    "\n",
    "        # Save to file\n",
    "        filename = f\"{EXPORT_PATH}book_{idx+1}.txt\"\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"Title: {title}\\n\")\n",
    "            f.write(f\"Author: {author}\\n\")\n",
    "            f.write(f\"Release Date: {release_date}\\n\")\n",
    "            f.write(f\"URL: {link}\\n\\n\")\n",
    "            f.write(f\"Summary:\\n{summary}\")\n",
    "\n",
    "        print(f\"Saved: {filename}\")\n",
    "\n",
    "finally:\n",
    "    browser.quit()\n",
    "\n",
    "print(\"Scraping complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use methods from Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Graph Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Setup PyKEEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Basic Embedding Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Convert your RDF triples to PyKEEN format\n",
    "triples = [(s, p, o) for s, p, o in g]\n",
    "tf = TriplesFactory.from_labeled_triples(triples)\n",
    "\n",
    "# Train a TransE model\n",
    "results = pipeline(\n",
    "    training=tf,\n",
    "    model='TransE',\n",
    "    epochs=100,\n",
    "    learning_rate=0.01,\n",
    "    training_batch_size=128,\n",
    "    random_seed=42,\n",
    ")\n",
    "\n",
    "# Access embeddings\n",
    "entity_embeddings =\n",
    "results.model.entity_embeddings.weight.detach().numpy()\n",
    "relation_embeddings =\n",
    "results.model.relation_embeddings.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate entity similarities\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def find_similar_entities(entity_id, entity_embeddings, top_k=5):\n",
    "    entity_vector = entity_embeddings[entity_id].reshape(1, -1)\n",
    "    similarities = cosine_similarity(entity_vector, entity_embeddings)\n",
    "    most_similar = np.argsort(similarities[0])[-top_k-1:-1][::-1]\n",
    "    return most_similar\n",
    "\n",
    "# Link prediction\n",
    "results.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips for Small Knowledge Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use simpler models like TransE or DistMult for small datasets\n",
    "- Avoid complex models that require large amounts of training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Increase the number of negative samples\n",
    "- Use smaller embedding dimensions (e.g., 50-100 instead of 200+)\n",
    "- Implement early stopping to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Example Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "results = pipeline(\n",
    "    training=tf,\n",
    "    model='TransE',\n",
    "    epochs=100,\n",
    "    embedding_dim=50,\n",
    "    learning_rate=0.01,\n",
    "    training_batch_size=32,\n",
    "    num_negs_per_pos=10,\n",
    "    early_stopping=True,\n",
    "    early_stopping_patience=5,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare embeddings before and after data augmentation\n",
    "- Use visualization tools to inspect entity clusters\n",
    "- Validate predictions against domain knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge : Limited Entity Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "\n",
    "# Split your triples into training (80%), validation (10%), and test (10%) sets\n",
    "training, validation, testing =\n",
    "TriplesFactory.from_labeled_triples(triples).split([0.8, 0.1, 0.1])\n",
    "\n",
    "print(f\"Training triples: {training.num_triples}\")\n",
    "print(f\"Validation triples: {validation.num_triples}\")\n",
    "print(f\"Testing triples: {testing.num_triples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Model Training with Multiple Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "# Dictionary to store results\n",
    "model_results = {}\n",
    "\n",
    "# Test different models\n",
    "models = ['TransE', 'DistMult', 'ComplEx']\n",
    "for model_name in models:\n",
    "    results = pipeline(\n",
    "    training=training,\n",
    "    validation=validation,\n",
    "    testing=testing,\n",
    "    model=model_name,\n",
    "    epochs=100,\n",
    "    embedding_dim=50,\n",
    "    training_kwargs=dict(batch_size=32),\n",
    "    random_seed=42,\n",
    "    )\n",
    "    model_results[model_name] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(results, model_name):\n",
    "    metrics = results.metric_results.to_dict()\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    print(f\"Mean Rank: {metrics['both']['mean_rank']:.2f}\")\n",
    "    print(f\"Mean Reciprocal Rank: {metrics['both']['mean_reciprocal_rank']:.4f}\")\n",
    "    print(f\"Hits@1: {metrics['both']['hits_at_1']:.4f}\")\n",
    "    print(f\"Hits@3: {metrics['both']['hits_at_3']:.4f}\")\n",
    "    print(f\"Hits@10: {metrics['both']['hits_at_10']:.4f}\")\n",
    "for model_name, results in model_results.items():\n",
    "    evaluate_model(results, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Entity Similarity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def analyze_entity_neighborhood(model, entity_id, k=5):\n",
    "    # Get entity embeddings\n",
    "    entity_embeddings = model.entity_embeddings.weight.detach().numpy()\n",
    "    entity_labels = model.triples_factory.entity_labels\n",
    "\n",
    "    # Calculate similarities\n",
    "    similarities = cosine_similarity([entity_embeddings[entity_id]], entity_embeddings)[0]\n",
    "    most_similar = np.argsort(similarities)[-k-1:-1][::-1]\n",
    "\n",
    "    print(f\"\\nMost similar entities to {entity_labels[entity_id]}:\")\n",
    "    for idx in most_similar:\n",
    "        print(f\"{entity_labels[idx]}: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Link Prediction Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_tail_entities(model, head, relation, k=5):\n",
    "    # Get predictions\n",
    "    predictions = model.predict_scores(\n",
    "        heads=torch.tensor([head]),\n",
    "        relations=torch.tensor([relation]),\n",
    "    )\n",
    "\n",
    "    # Get top k predictions\n",
    "    top_tails = torch.topk(predictions, k=k, dim=1)\n",
    "\n",
    "    return [(model.triples_factory.entity_labels[idx.item()],score.item())\n",
    "    for idx, score in zip(top_tails.indices[0], top_tails.values[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Visualization of Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_embeddings(model, entity_types=None):\n",
    "    # Get embeddings and reduce dimensionality\n",
    "    embeddings = model.entity_embeddings.weight.detach().numpy()\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    if entity_types is None:\n",
    "        plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.5)\n",
    "    else:\n",
    "        # Color by entity type\n",
    "        for entity_type, indices in entity_types.items():\n",
    "            plt.scatter(reduced_embeddings[indices, 0],\n",
    "                reduced_embeddings[indices, 1],\n",
    "                label=entity_type, alpha=0.5)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.title(\"Entity Embeddings Visualization\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Performance Comparison Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_table(model_results):\n",
    "    metrics = ['mean_rank', 'mean_reciprocal_rank', 'hits_at_10']\n",
    "    comparison = {model: {} for model in model_results.keys()}\n",
    "\n",
    "    for model_name, results in model_results.items():\n",
    "        for metric in metrics:\n",
    "            comparison[model_name][metric] = results.metric_results.to_dict()['both'][metric]\n",
    "\n",
    "    return pd.DataFrame(comparison).round(4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
