{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project : Web scrapping, knowledge base construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Web scrapping and knowledge base construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import inflect\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from datasets import load_dataset\n",
    "\n",
    "import spacy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "We laod the CoNLL-2003 from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Access the training, validation, and test sets\n",
    "train_dataset = dataset['train']\n",
    "validation_dataset = dataset['validation']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "# Print the first example from the training set\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 : Model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Text cleaning and prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\auria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "\n",
    "p = inflect.engine()\n",
    "# convert number into words\n",
    "def convert_number(text):\n",
    "    # split string into list of words\n",
    "    temp_str = text.split()\n",
    "    # initialise empty list\n",
    "    new_string = []\n",
    "\n",
    "    for word in temp_str:\n",
    "        # if word is a digit, convert the digit\n",
    "        # to numbers and append into the new_string list\n",
    "        if word.isdigit():\n",
    "            temp = p.number_to_words(word)\n",
    "            new_string.append(temp)\n",
    "\n",
    "        # append the word as it is\n",
    "        else:\n",
    "            new_string.append(word)\n",
    "\n",
    "    # join the words of new_string to form a string\n",
    "    temp_str = ' '.join(new_string)\n",
    "    return temp_str\n",
    "\n",
    "def replace_non_alphabetic_with_whitespace(text):\n",
    "    modified_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    return modified_text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stems = [stemmer.stem(word) for word in word_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet') \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemma_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pipeline(example):\n",
    "    text = \" \".join(example['tokens'])\n",
    "\n",
    "    text = text_lowercase(text)\n",
    "    text = convert_number(text)\n",
    "    text = replace_non_alphabetic_with_whitespace(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_whitespace(text)\n",
    "\n",
    "    # Convertir la liste en chaîne après avoir supprimé les stopwords\n",
    "    text = \" \".join(remove_stopwords(text))\n",
    "    text = \" \".join(stem_words(text))\n",
    "    text = \" \".join(lemma_words(text))\n",
    "\n",
    "    processed_example = {'tokens': text.split(), 'ner_tags': example['ner_tags']}\n",
    "    return processed_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ['0', '1', '2', '3', '4'], 'tokens': [['eu', 'reject', 'german', 'call', 'boycott', 'british', 'lamb'], ['peter', 'blackburn'], ['brussel'], ['european', 'commiss', 'said', 'thursday', 'disagre', 'german', 'advic', 'consum', 'shun', 'british', 'lamb', 'scientist', 'determin', 'whether', 'mad', 'cow', 'diseas', 'transmit', 'sheep'], ['germani', 'repres', 'european', 'union', 'veterinari', 'committe', 'werner', 'zwingmann', 'said', 'wednesday', 'consum', 'buy', 'sheepmeat', 'countri', 'britain', 'scientif', 'advic', 'clearer']], 'pos_tags': [[22, 42, 16, 21, 35, 37, 16, 21, 7], [22, 22], [22, 11], [12, 22, 22, 38, 15, 22, 28, 38, 15, 16, 21, 35, 24, 35, 37, 16, 21, 15, 24, 41, 15, 16, 21, 21, 20, 37, 40, 35, 21, 7], [22, 27, 21, 35, 12, 22, 22, 27, 16, 21, 22, 22, 38, 15, 22, 24, 20, 37, 21, 15, 24, 16, 15, 22, 15, 12, 16, 21, 38, 17, 7]], 'chunk_tags': [[11, 21, 11, 12, 21, 22, 11, 12, 0], [11, 12], [11, 12], [11, 12, 12, 21, 13, 11, 11, 21, 13, 11, 12, 13, 11, 21, 22, 11, 12, 17, 11, 21, 17, 11, 12, 12, 21, 22, 22, 13, 11, 0], [11, 11, 12, 13, 11, 12, 12, 11, 12, 12, 12, 12, 21, 13, 11, 12, 21, 22, 11, 13, 11, 1, 13, 11, 17, 11, 12, 12, 21, 1, 0]], 'ner_tags': [[3, 0, 7, 0, 0, 0, 7, 0, 0], [1, 2], [5, 0], [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "train_processed = train_dataset.map(preprocess_pipeline)\n",
    "validation_processed = validation_dataset.map(preprocess_pipeline)\n",
    "test_processed = test_dataset.map(preprocess_pipeline)\n",
    "\n",
    "print(train_processed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Named entity recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conditional Random Field (CRF) with sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.86      0.80      0.83      1668\n",
      "      B-MISC       0.83      0.75      0.79       702\n",
      "       B-ORG       0.77      0.73      0.75      1661\n",
      "       B-PER       0.83      0.85      0.84      1617\n",
      "       I-LOC       0.82      0.66      0.73       257\n",
      "      I-MISC       0.71      0.68      0.69       216\n",
      "       I-ORG       0.69      0.76      0.72       835\n",
      "       I-PER       0.87      0.95      0.91      1156\n",
      "           O       0.99      0.99      0.99     38323\n",
      "\n",
      "    accuracy                           0.96     46435\n",
      "   macro avg       0.82      0.80      0.80     46435\n",
      "weighted avg       0.96      0.96      0.96     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define features and labels for training\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        if isinstance(word1, str):  # Vérifiez que word1 est une chaîne de caractères\n",
    "            features.update({\n",
    "                '+1:word.lower()': word1.lower(),\n",
    "                '+1:word.istitle()': word1.istitle(),\n",
    "                '+1:word.isupper()': word1.isupper(),\n",
    "                '+1:postag': postag1,\n",
    "                '+1:postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: word1 is not a string at index {i+1}: {word1}\")\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "pos_tag_dict = dataset[\"train\"].features[\"pos_tags\"].feature.int2str\n",
    "ner_tag_dict = dataset[\"train\"].features[\"ner_tags\"].feature.int2str\n",
    "\n",
    "# Convert dataset into structured format with string POS and NER tags\n",
    "train_sents = [\n",
    "    list(zip(tokens, map(pos_tag_dict, pos_tags), map(ner_tag_dict, ner_tags)))\n",
    "    for tokens, pos_tags, ner_tags in zip(train_dataset[\"tokens\"], train_dataset[\"pos_tags\"], train_dataset[\"ner_tags\"])\n",
    "]\n",
    "\n",
    "test_sents = [\n",
    "    list(zip(tokens, map(pos_tag_dict, pos_tags), map(ner_tag_dict, ner_tags)))\n",
    "    for tokens, pos_tags, ner_tags in zip(test_dataset[\"tokens\"], test_dataset[\"pos_tags\"], test_dataset[\"ner_tags\"])\n",
    "]\n",
    "\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "\n",
    "# Train the CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=False\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.7.5 and may not be 100% compatible with the current version (3.8.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities: [('Apple', 'ORG', 0, 5), ('Steve Jobs', 'PER', 21, 31)]\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy's pre-trained NER model\n",
    "nlp = spacy.load(\"./best_ner_model\")\n",
    "\n",
    "# Example text\n",
    "text = \"Apple was founded by Steve Jobs.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(ent.text, ent.label_, ent.start_char, ent.end_char) for ent in doc.ents]\n",
    "print(\"Extracted Entities:\", entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comparition of the performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRF Model - Precision: 0.9557, Recall: 0.9559, F1-score: 0.9556\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# Calcul des métriques\n",
    "precision_crf = metrics.flat_precision_score(y_test, y_pred, average='weighted')\n",
    "recall_crf = metrics.flat_recall_score(y_test, y_pred, average='weighted')\n",
    "f1_score_crf = metrics.flat_f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"CRF Model - Precision: {precision_crf:.4f}, Recall: {recall_crf:.4f}, F1-score: {f1_score_crf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy NER Model - Precision: 0.8090, Recall: 0.8168, F1-score: 0.8129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\auria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "true_entities = []\n",
    "pred_entities = []\n",
    "\n",
    "for text, true_labels in zip(test_dataset[\"tokens\"], test_dataset[\"ner_tags\"]):\n",
    "    text_str = \" \".join(text)\n",
    "    doc = nlp(text_str)\n",
    "    \n",
    "    # Convert true labels to named entity format\n",
    "    true_labels = [ner_tag_dict(label) for label in true_labels]  \n",
    "    true_entities.append(true_labels)\n",
    "    \n",
    "    # Initialiser les labels prédits avec 'O' (Outside)\n",
    "    predicted_labels = [\"O\"] * len(text)\n",
    "    \n",
    "    # Associer les entités détectées aux tokens\n",
    "    for ent in doc.ents:\n",
    "        ent_text = ent.text.split()  # Séparer en tokens\n",
    "        for token in ent_text:\n",
    "            if token in text:  # Vérifier si le token est bien dans le texte d'origine\n",
    "                idx = text.index(token)  # Trouver l'index du token\n",
    "                predicted_labels[idx] = ent.label_  # Assigner l'entité\n",
    "        \n",
    "    pred_entities.append(predicted_labels)\n",
    "\n",
    "precision_spaCy, recall_spaCy, f1_spaCy, _ = precision_recall_fscore_support(\n",
    "    [label for sent in true_entities for label in sent], \n",
    "    [label for sent in pred_entities for label in sent], \n",
    "    average='weighted'\n",
    ")\n",
    "\n",
    "print(f\"spaCy NER Model - Precision: {precision_spaCy:.4f}, Recall: {recall_spaCy:.4f}, F1-score: {f1_spaCy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>spaCy</th>\n",
       "      <th>CRF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.955725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.816776</td>\n",
       "      <td>0.955938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F1-Score</td>\n",
       "      <td>0.812852</td>\n",
       "      <td>0.955620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     spaCy       CRF\n",
       "0  Precision  0.808966  0.955725\n",
       "1     Recall  0.816776  0.955938\n",
       "2   F1-Score  0.812852  0.955620"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Precision', 'Recall', 'F1-Score'],\n",
    "    'spaCy': [precision_spaCy, recall_spaCy, f1_spaCy],\n",
    "    'CRF': [precision_crf, recall_crf, f1_score_crf]\n",
    "})\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the CRF model has a better score for these 3 metrics, which means that CRF performs better than spaCy overall for the named entity recognition task on our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving the extracted entities along their positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted from CRF model saved in crf_entities.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Extraire les entités prédites par CRF\n",
    "crf_entities = []\n",
    "for sent, labels in zip(test_sents, y_pred):\n",
    "    for i, label in enumerate(labels):\n",
    "        if label != 'O':  # Exclure les tokens non annotés\n",
    "            crf_entities.append({\n",
    "                \"text\": sent[i][0],\n",
    "                \"entity\": label,\n",
    "                \"position\": i\n",
    "            })\n",
    "\n",
    "# Sauvegarde en JSON\n",
    "with open(\"crf_entities.json\", \"w\") as f:\n",
    "    json.dump(crf_entities, f, indent=4)\n",
    "\n",
    "print(\"Entities extracted from CRF model saved in crf_entities.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities extracted from spaCy model saved in spacy_entities.json\n"
     ]
    }
   ],
   "source": [
    "spacy_entities = []\n",
    "\n",
    "for text in test_dataset[\"tokens\"]:\n",
    "    sentence = \" \".join(text)\n",
    "    doc = nlp(sentence)\n",
    "    for ent in doc.ents:\n",
    "        spacy_entities.append({\n",
    "            \"text\": ent.text,\n",
    "            \"entity\": ent.label_,\n",
    "            \"start\": ent.start_char,\n",
    "            \"end\": ent.end_char\n",
    "        })\n",
    "\n",
    "# Sauvegarde en JSON\n",
    "with open(\"spacy_entities.json\", \"w\") as f:\n",
    "    json.dump(spacy_entities, f, indent=4)\n",
    "\n",
    "print(\"Entities extracted from spaCy model saved in spacy_entities.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Relation Extraction (RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Knowledge graph building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 : Pipeline for knowledge graph construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Fetch news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use methods from Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
